{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "za1hkIHK6I19"
   },
   "source": [
    "# Определим наш датасет\n",
    "Наш (воображаемый) датасет составлен из **1000 образцов данных** (data samples).\n",
    "\n",
    "* Каждый сэмпл имеет 100 признаков/свойств/параметров/features.\n",
    "* Параметр представляет собой нецелое число от 0 до 1\n",
    "* Сэмплы делятся на 10 категорий. Задачей нейросети будет определениеверной категории для данного сэмпла.\n",
    "* Мы будем использовать 800 сэмплов для **тренировки** и 200 сэмплов для **аттестации** (проверки).\n",
    "* Будеим использовать **размер пакета** (batch size) равный 10 для тренировки и аттестации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_TFFAryh5qzG"
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "#составление лога\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "sample_count = 1000\n",
    "train_count = 800\n",
    "valid_count = sample_count - train_count\n",
    "\n",
    "feature_count = 100\n",
    "category_count = 10\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZzzofwP7uku"
   },
   "source": [
    "# Генерация датасета\n",
    "Будем использовать равномерное распределение для генерации 1000 сэмплов. Они хранятся в NDArray 'X': **1000 строк, 100 колонок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1531154255953,
     "user": {
      "displayName": "Глеб Кирсанов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108640698260449341450"
     },
     "user_tz": -180
    },
    "id": "6yU9Sgey7TFq",
    "outputId": "71049888-47df-47dc-b2e5-b893e122c83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n",
      "[[5.48813522e-01 5.92844605e-01 7.15189338e-01 ... 6.07830644e-01\n",
      "  4.17021990e-01 9.97184813e-01]\n",
      " [7.20324516e-01 9.32557344e-01 1.14381080e-04 ... 1.85082078e-01\n",
      "  2.59262286e-02 9.31540847e-01]\n",
      " [5.49662471e-01 9.47730601e-01 4.35322404e-01 ... 8.39949071e-01\n",
      "  2.90904731e-01 1.21328577e-01]\n",
      " ...\n",
      " [8.18738341e-02 2.44539641e-02 8.53825390e-01 ... 6.76115692e-01\n",
      "  1.75401583e-01 9.24937129e-01]\n",
      " [3.79189700e-01 8.49168241e-01 7.75433898e-01 ... 4.59736548e-02\n",
      "  5.40907323e-01 8.03755522e-01]\n",
      " [5.59466481e-01 9.35443759e-01 5.55880964e-01 ... 1.00363605e-01\n",
      "  9.17030871e-01 4.12768424e-01]]\n"
     ]
    }
   ],
   "source": [
    "X = mx.nd.uniform(low=0, high=1, shape=(sample_count, feature_count))\n",
    "\n",
    "print(X.shape)\n",
    "print(X.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6BsTKxh8TTw"
   },
   "source": [
    "Категориями для этих сэмпллов будут являтся числами от 0 до 9, рандомно сгенерированных и хранящихся в 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1531154257331,
     "user": {
      "displayName": "Глеб Кирсанов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108640698260449341450"
     },
     "user_tz": -180
    },
    "id": "-pFZggt08OB7",
    "outputId": "7423dd93-58a1-4d3e-fe89-71857e12ce2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "[9. 9. 1. 8. 8. 4. 9. 6. 7. 9.]\n"
     ]
    }
   ],
   "source": [
    "Y = mx.nd.empty((sample_count,))\n",
    "for i in range(sample_count):\n",
    "    Y[i] = np.random.randint(0, category_count)\n",
    "    \n",
    "print(Y.shape)\n",
    "print(Y[0:10].asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IksbBLZ84QL"
   },
   "source": [
    "# Разделение набора данных\n",
    "Дальше мы разделим наш датасет в соотношении 80/20 для тренировки и валидации. Воспользуемся ```NDArray.crop``` функцией для этого. Тут датасет полностью случаен, поэтому мы можем использовать первые 80% для тренировки, а оставшиеся 20% для валидации. На реальном примере нам бы пришлось сначала **перемешать** данные, чтобы избежать возможных совпадений на последовательно-сгенерированных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T9nO9Yqb81kj"
   },
   "outputs": [],
   "source": [
    "X_train = mx.nd.crop(X, begin=(0,0), end=(train_count, feature_count))\n",
    "X_valid = mx.nd.crop(X, begin=(train_count,0), end=(sample_count, feature_count))\n",
    "\n",
    "Y_train = Y[ : train_count]\n",
    "Y_valid = Y[train_count : sample_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BXRRlLc-UAL"
   },
   "source": [
    "Наши данные готовы.\n",
    "\n",
    "# Построение сети\n",
    "Наша сеть очень простая. Посмотрим на каждый слой:\n",
    "* **input layer** представлен Символом 'data'. Мы свяжем его непосредственно с входными данными позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FEcOukcF-Me_"
   },
   "outputs": [],
   "source": [
    "data = mx.sym.Variable('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oE5ML6xd-9BG"
   },
   "source": [
    "*fc1* (fully-connected) - **первый hidden layer** построен из 64 полностью-связных нейронов, другими словами, каждый параметр во входном слое будет связан с 64 нейронами. Как вы можете видеть, мы используем высокоуровневую ```Symbol.FullyConnected``` функцию, которая более удобна, чем прописывание каждого соединения вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5lYEqt6E-4xj"
   },
   "outputs": [],
   "source": [
    "fc1 = mx.sym.FullyConnected(data, name='fully-connected1', num_hidden=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5JjOuz91_0U7"
   },
   "source": [
    "Каждый вывод fc1 проходит через [функцию активации ](https://en.wikipedia.org/wiki/Activation_function). Тут мы используем [rectified linear unit](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29) или 'relu'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NYL3dBXiARFu"
   },
   "outputs": [],
   "source": [
    "relu1 = mx.sym.Activation(fc1, name='relu1', act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkS8I4t8AYoI"
   },
   "source": [
    "*fc2* - второй скрытый слой, построенный из 10 полностью-связных нейронов, которые отображают наши 10 категорий. Каждый нейрон выводит дробное число, отмасштабированное произвольно. Наибольшее из 10 значений отобразит самую вероятную категорию сэмпла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NcrYzEPAAYE3"
   },
   "outputs": [],
   "source": [
    "fc2 = mx.sym.FullyConnected(relu1, name='fully-connected2', num_hidden=category_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYbIIVxWBIWz"
   },
   "source": [
    "**Результирующий слой** применит [Softmax](https://ru.wikipedia.org/wiki/Softmax) функцию к 10 значениям с fc2 слоя: они превратятся в 10 значений между 0 и 1, которые в сумме дадут 1. Каждое значение отразит **предсказанную вероятность для каждой категории**, наибольшее укажет на самую вероятную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ou3k48K0BHgq"
   },
   "outputs": [],
   "source": [
    "out = mx.sym.SoftmaxOutput(fc2, name='softmax')\n",
    "mod = mx.mod.Module(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJLyOh1PB6Mb"
   },
   "source": [
    "# Создание Итератора\n",
    "Нейросеть не тренеруется на одном сэмле в единицу времени, это неэффективно с точки зрения производительности. Вместо этого мы используем **пакеты** (batches), фиксированное число сэмплов, по-другому.\n",
    "\n",
    "Чтобы доставить эти пакеты сети, мы вынуждены построить итератор, используя ```NDArrayIter``` функцию. Это параметры наших данных для тренировки, категории (MXNet называет их **labels** (названия)) и размер пакета.\n",
    "\n",
    "Как вы видите, мы можем итерироваться по датасету, 10 сэмплов и 10 названий в единицу времени. Потом вызовем функцию ```reset()``` для восстановления итератора в начальное состояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1531154272888,
     "user": {
      "displayName": "Глеб Кирсанов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108640698260449341450"
     },
     "user_tz": -180
    },
    "id": "zs7oCesKB5IK",
    "outputId": "c42d3396-39be-4a9d-f683-87277dfd537e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[[5.48813522e-01 5.92844605e-01 7.15189338e-01 8.44265759e-01\n",
      "  6.02763355e-01 8.57945621e-01 5.44883192e-01 8.47251713e-01\n",
      "  4.23654795e-01 6.23563707e-01 6.45894110e-01 3.84381711e-01\n",
      "  4.37587202e-01 2.97534615e-01 8.91772985e-01 5.67129776e-02\n",
      "  9.63662744e-01 2.72656292e-01 3.83441508e-01 4.77665126e-01\n",
      "  7.91725039e-01 8.12168717e-01 5.28894901e-01 4.79977161e-01\n",
      "  5.68044543e-01 3.92784804e-01 9.25596654e-01 8.36078763e-01\n",
      "  7.10360557e-02 3.37396175e-01 8.71292949e-02 6.48171902e-01\n",
      "  2.02183984e-02 3.68241549e-01 8.32619846e-01 9.57155168e-01\n",
      "  7.78156757e-01 1.40350774e-01 8.70012164e-01 8.70087266e-01\n",
      "  9.78618324e-01 4.73608047e-01 7.99158573e-01 8.00910771e-01\n",
      "  4.61479366e-01 5.20477474e-01 7.80529201e-01 6.78879559e-01\n",
      "  1.18274420e-01 7.20632672e-01 6.39921010e-01 5.82019806e-01\n",
      "  1.43353283e-01 5.37373245e-01 9.44668889e-01 7.58615613e-01\n",
      "  5.21848321e-01 1.05907604e-01 4.14661944e-01 4.73600417e-01\n",
      "  2.64555603e-01 1.86332345e-01 7.74233699e-01 7.36918151e-01\n",
      "  4.56150323e-01 2.16550350e-01 5.68433940e-01 1.35218173e-01\n",
      "  1.87897980e-02 3.24140996e-01 6.17635489e-01 1.49674863e-01\n",
      "  6.12095714e-01 2.22321391e-01 6.16934001e-01 3.86488974e-01\n",
      "  9.43748057e-01 9.02598500e-01 6.81820273e-01 4.49949980e-01\n",
      "  3.59507889e-01 6.13063455e-01 4.37031955e-01 9.02348578e-01\n",
      "  6.97631180e-01 9.92803499e-02 6.02254681e-02 9.69809055e-01\n",
      "  6.66766703e-01 6.53140008e-01 6.70637846e-01 1.70909584e-01\n",
      "  2.10382566e-01 3.58152181e-01 1.28926292e-01 7.50686169e-01\n",
      "  3.15428346e-01 6.07830644e-01 4.17021990e-01 9.97184813e-01]\n",
      " [7.20324516e-01 9.32557344e-01 1.14381080e-04 1.28124446e-01\n",
      "  3.02332580e-01 9.99040544e-01 1.46755889e-01 2.36088976e-01\n",
      "  9.23385918e-02 3.96580726e-01 1.86260208e-01 3.87910753e-01\n",
      "  3.45560730e-01 6.69746041e-01 3.96767467e-01 9.35539067e-01\n",
      "  5.38816750e-01 8.46310914e-01 4.19194520e-01 3.13273519e-01\n",
      "  6.85219526e-01 5.24548173e-01 2.04452246e-01 4.43452895e-01\n",
      "  8.78117442e-01 2.29577214e-01 2.73875967e-02 5.34413934e-01\n",
      "  6.70467496e-01 9.13962007e-01 4.17304814e-01 4.57204819e-01\n",
      "  5.58689833e-01 4.30698574e-01 1.40386939e-01 9.39127803e-01\n",
      "  1.98101491e-01 7.78389215e-01 8.00744593e-01 7.15970516e-01\n",
      "  9.68261600e-01 8.02757502e-01 3.13424170e-01 9.28008109e-02\n",
      "  6.92322612e-01 5.18152535e-01 8.76389146e-01 8.65020275e-01\n",
      "  8.94606650e-01 8.29146922e-01 8.50442052e-02 8.29603374e-01\n",
      "  3.90547849e-02 2.73049980e-01 1.69830427e-01 5.92431985e-02\n",
      "  8.78142476e-01 6.70528054e-01 9.83468369e-02 5.93065500e-01\n",
      "  4.21107620e-01 6.71654105e-01 9.57889557e-01 4.11787868e-01\n",
      "  5.33165276e-01 1.97550893e-01 6.91877127e-01 2.89629638e-01\n",
      "  3.15515637e-01 1.42120138e-01 6.86500907e-01 7.83314466e-01\n",
      "  8.34625661e-01 4.12538856e-01 1.82882808e-02 3.41713093e-02\n",
      "  7.50144303e-01 6.24029994e-01 9.88861084e-01 6.60635710e-01\n",
      "  7.48165667e-01 2.98495293e-01 2.80443996e-01 4.46134508e-01\n",
      "  7.89279342e-01 2.22124547e-01 1.03226013e-01 7.33641759e-02\n",
      "  4.47893530e-01 4.69238520e-01 9.08595502e-01 9.61722583e-02\n",
      "  2.93614149e-01 9.03370142e-01 2.87775338e-01 1.19490474e-01\n",
      "  4.35994893e-01 1.85082078e-01 2.59262286e-02 9.31540847e-01]\n",
      " [5.49662471e-01 9.47730601e-01 4.35322404e-01 4.84749109e-01\n",
      "  4.20367807e-01 3.20536435e-01 3.30334812e-01 1.54426679e-01\n",
      "  2.04648629e-01 6.98862672e-01 6.19270980e-01 1.19950540e-01\n",
      "  2.99654663e-01 4.85175908e-01 2.66827285e-01 6.32737756e-01\n",
      "  6.21133804e-01 8.18226695e-01 5.29142082e-01 6.83026016e-01\n",
      "  1.34579942e-01 4.98561174e-01 5.13578117e-01 5.86796999e-01\n",
      "  1.84439868e-01 7.19754219e-01 7.85335124e-01 2.58498073e-01\n",
      "  8.53975296e-01 5.46207309e-01 4.94236827e-01 4.07307833e-01\n",
      "  8.46561491e-01 1.76984623e-01 7.96454698e-02 9.69632387e-01\n",
      "  5.05246103e-01 2.97018349e-01 6.52865022e-02 2.87868828e-01\n",
      "  4.28122342e-01 1.16193324e-01 9.65309218e-02 1.81727037e-01\n",
      "  1.27159968e-01 4.94289756e-01 5.96745312e-01 5.65765142e-01\n",
      "  2.26012006e-01 2.21835166e-01 1.06945686e-01 7.67491162e-01\n",
      "  2.20306203e-01 5.77308059e-01 3.49826276e-01 1.67823315e-01\n",
      "  4.67787474e-01 3.67471367e-01 2.01743230e-01 4.68673587e-01\n",
      "  6.40406728e-01 6.54266179e-01 4.83069837e-01 7.93089747e-01\n",
      "  5.05236745e-01 6.63061798e-01 3.86892647e-01 6.13029718e-01\n",
      "  7.93637455e-01 9.90851998e-01 5.80004156e-01 1.19484797e-01\n",
      "  1.62298605e-01 1.48564786e-01 7.00752318e-01 8.52281034e-01\n",
      "  9.64551091e-01 5.09525895e-01 5.00008345e-01 2.17269927e-01\n",
      "  8.89520049e-01 9.93266284e-01 3.41613650e-01 3.15297484e-01\n",
      "  5.67144156e-01 2.58733183e-01 4.27545965e-01 8.09175313e-01\n",
      "  4.36747253e-01 3.53675365e-01 7.76559174e-01 4.67842489e-01\n",
      "  5.35604179e-01 2.74173260e-01 5.50797880e-01 7.07248822e-02\n",
      "  7.08147824e-01 8.39949071e-01 2.90904731e-01 1.21328577e-01]\n",
      " [5.10827601e-01 5.69311321e-01 8.92946959e-01 4.37061936e-01\n",
      "  8.96293104e-01 1.87480096e-02 1.25585318e-01 4.06307392e-02\n",
      "  2.07242876e-01 2.47888297e-01 5.14672063e-02 9.35514942e-02\n",
      "  4.40809846e-01 6.94823682e-01 2.98762135e-02 1.45370141e-01\n",
      "  4.56833214e-01 4.53172296e-01 6.49144053e-01 2.15577006e-01\n",
      "  2.78487295e-01 3.53905082e-01 6.76254928e-01 4.92635936e-01\n",
      "  5.90862811e-01 9.13301468e-01 2.39818841e-02 7.65826404e-01\n",
      "  5.58854103e-01 9.73648250e-01 2.59252459e-01 4.02360648e-01\n",
      "  4.15101200e-01 5.52771926e-01 2.83525079e-01 3.06360632e-01\n",
      "  6.93137944e-01 5.86619973e-01 4.40453708e-01 2.74920106e-01\n",
      "  1.56867743e-01 4.54607755e-01 5.44649005e-01 7.57665217e-01\n",
      "  7.80314744e-01 8.17570746e-01 3.06363523e-01 2.57585287e-01\n",
      "  2.21957877e-01 8.93065095e-01 3.87971252e-01 7.18421996e-01\n",
      "  9.36383665e-01 2.06145011e-02 9.75995421e-01 1.42717332e-01\n",
      "  6.72383666e-01 3.25306177e-01 9.02834117e-01 8.08929205e-01\n",
      "  8.45750868e-01 3.98990959e-01 3.77994031e-01 4.24701601e-01\n",
      "  9.22170132e-02 4.13718671e-01 6.53410912e-01 7.87138522e-01\n",
      "  5.57840765e-01 7.13565767e-01 3.61564755e-01 2.31175683e-02\n",
      "  2.25054502e-01 3.15767258e-01 4.06519920e-01 5.62770069e-01\n",
      "  4.68940258e-01 7.48157442e-01 2.69235581e-01 6.09623671e-01\n",
      "  2.91792780e-01 2.03354523e-01 4.57686394e-01 6.53630853e-01\n",
      "  8.60533893e-01 6.62686288e-01 5.86252928e-01 8.71072054e-01\n",
      "  2.83487856e-01 8.11227739e-01 2.77977496e-01 3.74124736e-01\n",
      "  9.67029810e-01 9.00621474e-01 5.47232270e-01 1.72695324e-01\n",
      "  9.72684383e-01 8.55620921e-01 7.14815974e-01 6.09035611e-01]\n",
      " [6.97728813e-01 5.97556233e-01 2.16089502e-01 1.41464174e-01\n",
      "  9.76274431e-01 2.24505931e-01 6.23025699e-03 6.98420227e-01\n",
      "  2.52982348e-01 9.03178513e-01 4.34791535e-01 6.32963121e-01\n",
      "  7.79382944e-01 5.15914988e-03 1.97685078e-01 5.72356462e-01\n",
      "  8.62993240e-01 3.61496329e-01 9.83400702e-01 6.04131937e-01\n",
      "  1.63842246e-01 3.91766191e-01 5.97333968e-01 8.11947763e-01\n",
      "  8.98609497e-03 6.12525344e-01 3.86571288e-01 2.66473770e-01\n",
      "  4.41600531e-02 6.43914282e-01 9.56652939e-01 8.11062098e-01\n",
      "  4.36146647e-01 1.90247409e-02 9.48977292e-01 3.97803634e-02\n",
      "  7.86305964e-01 9.45003867e-01 8.66289318e-01 4.46349204e-01\n",
      "  1.73165426e-01 4.41348523e-01 7.49485865e-02 6.57095388e-02\n",
      "  6.00742698e-01 1.75861239e-01 1.67972177e-01 8.65882754e-01\n",
      "  7.33380139e-01 8.43528092e-01 4.08443868e-01 9.25153136e-01\n",
      "  5.27908802e-01 8.70306492e-01 9.37571585e-01 8.35256696e-01\n",
      "  5.21696150e-01 2.60972083e-01 1.08193390e-01 3.57581899e-02\n",
      "  1.58223405e-01 2.28762671e-01 5.45202672e-01 2.11180553e-01\n",
      "  5.24404109e-01 1.80720598e-01 6.37610257e-01 3.16116214e-01\n",
      "  4.01495457e-01 2.41038606e-01 6.49805129e-01 3.75368446e-01\n",
      "  3.96899998e-01 6.32663965e-01 6.23916090e-01 2.23032519e-01\n",
      "  7.67404974e-01 1.38751209e-01 1.78973913e-01 5.76996982e-01\n",
      "  3.75575781e-01 3.51673722e-01 5.02533078e-01 4.67750341e-01\n",
      "  6.86667085e-01 3.58766377e-01 2.53679663e-01 8.31690952e-02\n",
      "  5.54740846e-01 2.52909601e-01 2.21993178e-01 5.51801212e-02\n",
      "  8.70732307e-01 8.31327856e-01 2.06719160e-01 3.63736898e-01\n",
      "  9.18610930e-01 9.79444981e-01 4.88411188e-01 8.98210332e-02]\n",
      " [6.11743867e-01 3.96736592e-01 7.65907884e-01 3.54138047e-01\n",
      "  5.18418014e-01 4.86638010e-01 2.96800494e-01 9.90820944e-01\n",
      "  1.87721223e-01 8.08281660e-01 8.07412714e-02 6.49458885e-01\n",
      "  7.38440275e-01 8.19472790e-01 4.41309214e-01 2.42540404e-01\n",
      "  1.58309862e-01 7.64372587e-01 8.79937053e-01 1.10900767e-01\n",
      "  2.74086475e-01 2.04154745e-01 4.14235026e-01 1.19095363e-01\n",
      "  2.96079934e-01 8.77903044e-01 6.28787935e-01 5.23675263e-01\n",
      "  5.79837799e-01 4.92136002e-01 5.99929214e-01 7.31871128e-01\n",
      "  2.65819132e-01 1.45807508e-02 2.84685880e-01 9.33630317e-02\n",
      "  2.53588200e-01 8.26554239e-01 3.27563941e-01 8.33492756e-01\n",
      "  1.44164294e-01 8.92410994e-01 1.65612862e-01 9.58013475e-01\n",
      "  9.63930547e-01 5.61337113e-01 9.60226715e-01 9.05486941e-02\n",
      "  1.88414648e-01 9.95988905e-01 2.43065599e-02 4.77401733e-01\n",
      "  2.04555541e-01 6.84915602e-01 6.99843585e-01 8.43375266e-01\n",
      "  7.79514611e-01 6.16124809e-01 2.29330920e-02 5.63187480e-01\n",
      "  5.77662885e-01 3.68162185e-01 1.64217013e-03 6.90931201e-01\n",
      "  5.15472591e-01 8.16167653e-01 6.39795184e-01 9.25643504e-01\n",
      "  9.85624433e-01 5.73506113e-03 2.59097606e-01 7.20559597e-01\n",
      "  8.02496910e-01 6.67059124e-01 8.70483100e-01 1.99765399e-01\n",
      "  9.22749639e-01 6.96664929e-01 2.21421523e-03 5.75413704e-01\n",
      "  4.69488382e-01 5.79721391e-01 9.81468737e-01 6.45068958e-02\n",
      "  3.98944795e-01 1.77246124e-01 8.13732505e-01 3.41527075e-01\n",
      "  8.92860174e-01 9.47476089e-01 3.31979811e-01 2.09406361e-01\n",
      "  8.21229100e-01 6.42546043e-02 4.16966267e-02 3.70109409e-01\n",
      "  1.07656673e-01 9.85028803e-01 5.95052063e-01 9.94716883e-02]\n",
      " [5.29817343e-01 6.08473599e-01 4.18807417e-01 5.30396461e-01\n",
      "  3.35407853e-01 4.82832700e-01 6.22519433e-01 8.25209260e-01\n",
      "  4.38141435e-01 7.55012989e-01 7.35882103e-01 3.89975578e-01\n",
      "  5.18036425e-01 2.39813790e-01 5.78858614e-01 1.55615091e-01\n",
      "  6.45355105e-01 7.24328756e-01 9.90224242e-01 9.14195418e-01\n",
      "  8.19858193e-01 4.73026156e-01 4.13200945e-01 6.78503871e-01\n",
      "  8.76267672e-01 8.01720917e-01 8.23759437e-01 4.58184570e-01\n",
      "  5.44745028e-02 6.73834682e-01 7.18637228e-01 1.47844687e-01\n",
      "  8.02170575e-01 3.57095271e-01 7.36406624e-01 6.16476595e-01\n",
      "  7.09131777e-01 4.42510515e-01 5.40936828e-01 5.75952351e-01\n",
      "  1.24824174e-01 8.48412663e-02 9.57647324e-01 2.23283604e-01\n",
      "  4.03256297e-01 2.17890218e-01 2.16951162e-01 8.25591981e-01\n",
      "  7.17275858e-01 4.60241407e-01 9.94207442e-01 5.45692384e-01\n",
      "  2.55614042e-01 7.87609756e-01 6.71309412e-01 7.39860833e-01\n",
      "  5.99005938e-01 7.20097601e-01 7.17332125e-01 7.97826290e-01\n",
      "  9.37349558e-01 8.81896377e-01 3.51809770e-01 8.21604669e-01\n",
      "  2.53634095e-01 3.05941314e-01 4.02472496e-01 7.45375156e-01\n",
      "  7.46510744e-01 3.88219237e-01 7.24070549e-01 4.69667643e-01\n",
      "  4.06107783e-01 7.10044384e-01 9.89379823e-01 3.65126640e-01\n",
      "  4.50499266e-01 9.27250326e-01 3.73808444e-01 7.32187092e-01\n",
      "  7.09628582e-01 2.43837088e-01 8.24585557e-02 6.79664373e-01\n",
      "  3.98372918e-01 5.95788993e-02 7.63082877e-02 2.27339074e-01\n",
      "  7.79918790e-01 3.18972230e-01 4.38409239e-01 9.78222907e-01\n",
      "  7.23465204e-01 4.55584913e-01 9.77989495e-01 3.08012754e-01\n",
      "  5.38495898e-01 2.63870835e-01 5.01120448e-01 8.67434368e-02]\n",
      " [7.20511302e-02 4.19372201e-01 2.68438995e-01 1.59103591e-02\n",
      "  4.99882489e-01 5.27764797e-01 6.79229975e-01 8.68801475e-01\n",
      "  8.03739011e-01 3.30839247e-01 3.80941123e-01 3.92942309e-01\n",
      "  6.59363419e-02 6.74330413e-01 2.88145602e-01 6.72317266e-01\n",
      "  9.09593523e-01 6.94031596e-01 2.13385358e-01 3.45972925e-01\n",
      "  4.52123970e-01 9.29528177e-01 9.31206048e-01 2.62583762e-01\n",
      "  2.48992275e-02 7.50762701e-01 6.00548923e-01 2.54894048e-01\n",
      "  9.50129509e-01 8.51294577e-01 2.30302885e-01 1.74052760e-01\n",
      "  5.48489928e-01 7.90763497e-01 9.09128368e-01 9.37629342e-01\n",
      "  1.33169442e-01 4.48825806e-01 5.23412585e-01 3.84649575e-01\n",
      "  7.50409842e-01 3.57475251e-01 6.69013262e-01 1.93355620e-01\n",
      "  4.67752874e-01 1.00473970e-01 2.04849094e-01 4.82636899e-01\n",
      "  4.90765899e-01 6.13703489e-01 3.72384697e-01 9.51248348e-01\n",
      "  4.77401167e-01 3.48756373e-01 3.65890384e-01 2.76514709e-01\n",
      "  8.37917984e-01 4.46505904e-01 7.68647492e-01 9.57913756e-01\n",
      "  3.13994676e-01 1.79576889e-01 5.72625339e-01 1.42715752e-01\n",
      "  2.76049048e-01 8.35080966e-02 4.52842921e-01 5.47235131e-01\n",
      "  3.52978379e-01 3.10209244e-01 6.57399476e-01 2.82719731e-01\n",
      "  3.70351076e-01 9.20993567e-01 4.59092975e-01 4.33342159e-01\n",
      "  7.19324112e-01 4.18757230e-01 4.12991822e-01 9.86223161e-01\n",
      "  9.06423271e-01 7.93569982e-01 1.80451617e-01 3.43305111e-01\n",
      "  8.73429418e-01 1.11144381e-02 9.68540668e-01 2.39439577e-01\n",
      "  8.69194567e-01 3.77516985e-01 5.30855715e-01 8.16461265e-01\n",
      "  2.32728332e-01 4.22350794e-01 1.13988034e-02 6.12033308e-01\n",
      "  4.30468827e-01 7.66062915e-01 4.02351350e-01 4.01925117e-01]\n",
      " [5.22674680e-01 8.72088611e-01 4.78391796e-01 9.26438391e-01\n",
      "  5.55356503e-01 1.46524683e-01 5.43386042e-01 7.01527894e-01\n",
      "  7.60895550e-01 4.02677357e-01 7.12374568e-01 8.18265975e-01\n",
      "  6.19682074e-01 2.12813243e-02 4.26091760e-01 3.52811992e-01\n",
      "  2.89075017e-01 4.82124090e-01 9.73855257e-01 8.74815881e-01\n",
      "  3.33774060e-01 5.38107902e-02 2.18801066e-01 2.67227143e-01\n",
      "  6.58083931e-02 2.92142481e-01 9.82870519e-01 6.76520109e-01\n",
      "  1.27855718e-01 3.00618023e-01 3.22130799e-01 1.82702795e-01\n",
      "  7.09428415e-02 4.40228403e-01 2.24769935e-01 5.30989707e-01\n",
      "  3.93634915e-01 9.45203900e-01 8.96144986e-01 5.13627768e-01\n",
      "  3.45461607e-01 6.73571289e-01 9.84749436e-01 1.21707603e-01\n",
      "  2.87320539e-02 3.32638264e-01 3.51684749e-01 2.74454713e-01\n",
      "  3.80958885e-01 5.70344865e-01 7.64160156e-01 6.60120726e-01\n",
      "  9.38803911e-01 2.82080740e-01 3.19689810e-01 1.46586880e-01\n",
      "  4.32475924e-01 1.13810331e-01 2.70145744e-01 6.65281594e-01\n",
      "  8.01055908e-01 6.37549385e-02 6.38238788e-01 4.79277849e-01\n",
      "  6.86901286e-02 6.48770630e-01 6.03644490e-01 1.38011798e-01\n",
      "  7.95574546e-01 6.86940491e-01 3.20081599e-02 3.29390541e-02\n",
      "  4.55447823e-01 9.05606508e-01 7.90172517e-01 2.26410776e-01\n",
      "  9.88596499e-01 5.69935620e-01 5.83964527e-01 2.61256933e-01\n",
      "  3.89122963e-02 1.80812210e-01 1.03741586e-02 3.64461035e-01\n",
      "  5.01874566e-01 4.99130368e-01 4.95773286e-01 7.54310004e-03\n",
      "  1.33829534e-01 3.16224307e-01 1.42111093e-01 1.33220106e-02\n",
      "  2.18558669e-01 8.77221227e-01 4.18508172e-01 1.37526825e-01\n",
      "  2.48101175e-01 1.38613284e-01 8.40596557e-02 3.95885855e-01]\n",
      " [3.45498651e-01 4.94654506e-01 1.66776344e-01 3.15708876e-01\n",
      "  8.78559113e-01 3.73951167e-01 9.50964034e-01 7.34658062e-01\n",
      "  3.87483761e-02 9.67904091e-01 6.99107409e-01 7.01548457e-01\n",
      "  5.72759807e-01 1.35425150e-01 8.98007095e-01 1.36006981e-01\n",
      "  6.66898966e-01 9.50807154e-01 5.47837794e-01 5.53055704e-01\n",
      "  7.02427447e-01 9.43306923e-01 3.86477172e-01 6.29551053e-01\n",
      "  6.94438696e-01 5.64869702e-01 8.24870467e-01 6.39568210e-01\n",
      "  4.65668470e-01 7.65018404e-01 9.40524399e-01 3.75209332e-01\n",
      "  8.03739786e-01 8.34295809e-01 9.83359277e-01 1.04457960e-01\n",
      "  1.69636264e-01 7.93159977e-02 5.21084726e-01 6.76695630e-02\n",
      "  9.45517421e-01 4.90979671e-01 6.49540484e-01 2.09466830e-01\n",
      "  8.60831916e-01 9.25223470e-01 9.70845997e-01 9.80610549e-01\n",
      "  1.85541689e-01 6.69630587e-01 2.43115678e-01 5.81751406e-01\n",
      "  8.73400807e-01 7.94317424e-01 9.06277299e-01 4.67000343e-02\n",
      "  7.58278012e-01 5.80260217e-01 3.46901953e-01 7.45112896e-02\n",
      "  4.63534713e-01 1.60070032e-01 6.10537767e-01 4.34888721e-01\n",
      "  4.96281713e-01 5.93764186e-01 4.77974027e-01 1.40158162e-01\n",
      "  4.35555458e-01 8.98922980e-01 8.70408297e-01 9.78719532e-01\n",
      "  1.87358648e-01 9.29737866e-01 6.87674105e-01 3.92781138e-01\n",
      "  7.03529179e-01 2.89339453e-01 9.25200105e-01 3.16752493e-01\n",
      "  7.71320641e-01 2.98761159e-01 2.07519457e-02 4.94589925e-01\n",
      "  6.33648217e-01 4.43014950e-01 7.48803854e-01 8.31911385e-01\n",
      "  4.98507023e-01 5.83321750e-01 2.24796653e-01 2.51717344e-02\n",
      "  1.98062867e-01 7.09208012e-01 7.60530710e-01 2.65566140e-01\n",
      "  1.69110835e-01 2.63602853e-01 8.83398131e-02 1.50377870e-01]]\n",
      "<NDArray 10x100 @cpu(0)>]\n",
      "[\n",
      "[9. 9. 1. 8. 8. 4. 9. 6. 7. 9.]\n",
      "<NDArray 10 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "train_iter = mx.io.NDArrayIter(data=X_train, label=Y_train, batch_size=batch_size)\n",
    "\n",
    "for batch in train_iter: #для пакета в итераторе\n",
    "    print(batch.data)\n",
    "    print(batch.label)\n",
    "    break\n",
    "\n",
    "train_iter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1xROa5NER8h"
   },
   "source": [
    "Сеть готова учиться.\n",
    "# Тренируем модель\n",
    "Сперва свяжем входящий символ с датасетом (сэмплы и названия). Тут и нужен итератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YUEqKWjbDiiv"
   },
   "outputs": [],
   "source": [
    "mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcmHD4geE3mO"
   },
   "source": [
    "Дальше инициализируем веса нейронов. Это очень важный шаг: инициализирующий их \"правильным\" способ поможет сети учиться намного быстрее. Инициализатор Завьера (Xavier) - один из способов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1531074233018,
     "user": {
      "displayName": "Глеб Кирсанов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108640698260449341450"
     },
     "user_tz": -180
    },
    "id": "FdhRm-K-E2ZK",
    "outputId": "ddcd92cf-70f0-49a1-fe2a-14acf9815167"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Допустимо, но неэффективно\n",
    "mod.init_params()\n",
    "#Много лучше\n",
    "mod.init_params(initializer=mx.init.Xavier(magnitude=2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gU1fJF2FoRN"
   },
   "source": [
    "Теперь нужно определить параметры оптимизации:\n",
    "* будем использовать [Стохастический градиентный спуск](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) (Stochastic gradient descent или SGD), который долго использовался в ML и DL приложениях.\n",
    "* установим **learning rate** равный 0.1, типичное значение для SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "011i-YntFWXF"
   },
   "outputs": [],
   "source": [
    "mod.init_optimizer(optimizer='sgd', optimizer_params=(('learning_rate', 0.1), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TFkNTFLG0x-"
   },
   "source": [
    "Теперь можно тренировать сеть. Проведём 100 эпох, что значит - все данные 100 раз пройдут через сеть (в пакетах по 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3689
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8295,
     "status": "ok",
     "timestamp": 1531074242094,
     "user": {
      "displayName": "Глеб Кирсанов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108640698260449341450"
     },
     "user_tz": -180
    },
    "id": "3bZ9-CeEGe2Q",
    "outputId": "1335f467-7203-4034-8b39-ced46b2c782d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/gleb/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Train-accuracy=0.091250\n",
      "INFO:root:Epoch[0] Time cost=0.271\n",
      "INFO:root:Epoch[1] Train-accuracy=0.096250\n",
      "INFO:root:Epoch[1] Time cost=0.065\n",
      "INFO:root:Epoch[2] Train-accuracy=0.097500\n",
      "INFO:root:Epoch[2] Time cost=0.076\n",
      "INFO:root:Epoch[3] Train-accuracy=0.090000\n",
      "INFO:root:Epoch[3] Time cost=0.078\n",
      "INFO:root:Epoch[4] Train-accuracy=0.091250\n",
      "INFO:root:Epoch[4] Time cost=0.076\n",
      "INFO:root:Epoch[5] Train-accuracy=0.090000\n",
      "INFO:root:Epoch[5] Time cost=0.079\n",
      "INFO:root:Epoch[6] Train-accuracy=0.090000\n",
      "INFO:root:Epoch[6] Time cost=0.068\n",
      "INFO:root:Epoch[7] Train-accuracy=0.090000\n",
      "INFO:root:Epoch[7] Time cost=0.063\n",
      "INFO:root:Epoch[8] Train-accuracy=0.092500\n",
      "INFO:root:Epoch[8] Time cost=0.084\n",
      "INFO:root:Epoch[9] Train-accuracy=0.103750\n",
      "INFO:root:Epoch[9] Time cost=0.075\n",
      "INFO:root:Epoch[10] Train-accuracy=0.102500\n",
      "INFO:root:Epoch[10] Time cost=0.073\n",
      "INFO:root:Epoch[11] Train-accuracy=0.106250\n",
      "INFO:root:Epoch[11] Time cost=0.078\n",
      "INFO:root:Epoch[12] Train-accuracy=0.110000\n",
      "INFO:root:Epoch[12] Time cost=0.080\n",
      "INFO:root:Epoch[13] Train-accuracy=0.120000\n",
      "INFO:root:Epoch[13] Time cost=0.076\n",
      "INFO:root:Epoch[14] Train-accuracy=0.131250\n",
      "INFO:root:Epoch[14] Time cost=0.073\n",
      "INFO:root:Epoch[15] Train-accuracy=0.150000\n",
      "INFO:root:Epoch[15] Time cost=0.070\n",
      "INFO:root:Epoch[16] Train-accuracy=0.165000\n",
      "INFO:root:Epoch[16] Time cost=0.071\n",
      "INFO:root:Epoch[17] Train-accuracy=0.181250\n",
      "INFO:root:Epoch[17] Time cost=0.073\n",
      "INFO:root:Epoch[18] Train-accuracy=0.190000\n",
      "INFO:root:Epoch[18] Time cost=0.137\n",
      "INFO:root:Epoch[19] Train-accuracy=0.201250\n",
      "INFO:root:Epoch[19] Time cost=0.078\n",
      "INFO:root:Epoch[20] Train-accuracy=0.213750\n",
      "INFO:root:Epoch[20] Time cost=0.079\n",
      "INFO:root:Epoch[21] Train-accuracy=0.230000\n",
      "INFO:root:Epoch[21] Time cost=0.065\n",
      "INFO:root:Epoch[22] Train-accuracy=0.245000\n",
      "INFO:root:Epoch[22] Time cost=0.086\n",
      "INFO:root:Epoch[23] Train-accuracy=0.256250\n",
      "INFO:root:Epoch[23] Time cost=0.078\n",
      "INFO:root:Epoch[24] Train-accuracy=0.270000\n",
      "INFO:root:Epoch[24] Time cost=0.077\n",
      "INFO:root:Epoch[25] Train-accuracy=0.283750\n",
      "INFO:root:Epoch[25] Time cost=0.121\n",
      "INFO:root:Epoch[26] Train-accuracy=0.301250\n",
      "INFO:root:Epoch[26] Time cost=0.108\n",
      "INFO:root:Epoch[27] Train-accuracy=0.305000\n",
      "INFO:root:Epoch[27] Time cost=0.081\n",
      "INFO:root:Epoch[28] Train-accuracy=0.325000\n",
      "INFO:root:Epoch[28] Time cost=0.085\n",
      "INFO:root:Epoch[29] Train-accuracy=0.330000\n",
      "INFO:root:Epoch[29] Time cost=0.121\n",
      "INFO:root:Epoch[30] Train-accuracy=0.342500\n",
      "INFO:root:Epoch[30] Time cost=0.090\n",
      "INFO:root:Epoch[31] Train-accuracy=0.352500\n",
      "INFO:root:Epoch[31] Time cost=0.079\n",
      "INFO:root:Epoch[32] Train-accuracy=0.381250\n",
      "INFO:root:Epoch[32] Time cost=0.087\n",
      "INFO:root:Epoch[33] Train-accuracy=0.392500\n",
      "INFO:root:Epoch[33] Time cost=0.089\n",
      "INFO:root:Epoch[34] Train-accuracy=0.407500\n",
      "INFO:root:Epoch[34] Time cost=0.070\n",
      "INFO:root:Epoch[35] Train-accuracy=0.427500\n",
      "INFO:root:Epoch[35] Time cost=0.053\n",
      "INFO:root:Epoch[36] Train-accuracy=0.438750\n",
      "INFO:root:Epoch[36] Time cost=0.073\n",
      "INFO:root:Epoch[37] Train-accuracy=0.447500\n",
      "INFO:root:Epoch[37] Time cost=0.086\n",
      "INFO:root:Epoch[38] Train-accuracy=0.465000\n",
      "INFO:root:Epoch[38] Time cost=0.075\n",
      "INFO:root:Epoch[39] Train-accuracy=0.481250\n",
      "INFO:root:Epoch[39] Time cost=0.068\n",
      "INFO:root:Epoch[40] Train-accuracy=0.498750\n",
      "INFO:root:Epoch[40] Time cost=0.069\n",
      "INFO:root:Epoch[41] Train-accuracy=0.500000\n",
      "INFO:root:Epoch[41] Time cost=0.075\n",
      "INFO:root:Epoch[42] Train-accuracy=0.511250\n",
      "INFO:root:Epoch[42] Time cost=0.054\n",
      "INFO:root:Epoch[43] Train-accuracy=0.541250\n",
      "INFO:root:Epoch[43] Time cost=0.073\n",
      "INFO:root:Epoch[44] Train-accuracy=0.543750\n",
      "INFO:root:Epoch[44] Time cost=0.055\n",
      "INFO:root:Epoch[45] Train-accuracy=0.568750\n",
      "INFO:root:Epoch[45] Time cost=0.071\n",
      "INFO:root:Epoch[46] Train-accuracy=0.582500\n",
      "INFO:root:Epoch[46] Time cost=0.085\n",
      "INFO:root:Epoch[47] Train-accuracy=0.592500\n",
      "INFO:root:Epoch[47] Time cost=0.106\n",
      "INFO:root:Epoch[48] Train-accuracy=0.621250\n",
      "INFO:root:Epoch[48] Time cost=0.097\n",
      "INFO:root:Epoch[49] Train-accuracy=0.627500\n",
      "INFO:root:Epoch[49] Time cost=0.072\n",
      "INFO:root:Epoch[50] Train-accuracy=0.657500\n",
      "INFO:root:Epoch[50] Time cost=0.081\n",
      "INFO:root:Epoch[51] Train-accuracy=0.697500\n",
      "INFO:root:Epoch[51] Time cost=0.096\n",
      "INFO:root:Epoch[52] Train-accuracy=0.707500\n",
      "INFO:root:Epoch[52] Time cost=0.152\n",
      "INFO:root:Epoch[53] Train-accuracy=0.722500\n",
      "INFO:root:Epoch[53] Time cost=0.151\n",
      "INFO:root:Epoch[54] Train-accuracy=0.741250\n",
      "INFO:root:Epoch[54] Time cost=0.168\n",
      "INFO:root:Epoch[55] Train-accuracy=0.767500\n",
      "INFO:root:Epoch[55] Time cost=0.075\n",
      "INFO:root:Epoch[56] Train-accuracy=0.785000\n",
      "INFO:root:Epoch[56] Time cost=0.075\n",
      "INFO:root:Epoch[57] Train-accuracy=0.806250\n",
      "INFO:root:Epoch[57] Time cost=0.081\n",
      "INFO:root:Epoch[58] Train-accuracy=0.823750\n",
      "INFO:root:Epoch[58] Time cost=0.053\n",
      "INFO:root:Epoch[59] Train-accuracy=0.838750\n",
      "INFO:root:Epoch[59] Time cost=0.056\n",
      "INFO:root:Epoch[60] Train-accuracy=0.863750\n",
      "INFO:root:Epoch[60] Time cost=0.058\n",
      "INFO:root:Epoch[61] Train-accuracy=0.890000\n",
      "INFO:root:Epoch[61] Time cost=0.080\n",
      "INFO:root:Epoch[62] Train-accuracy=0.905000\n",
      "INFO:root:Epoch[62] Time cost=0.083\n",
      "INFO:root:Epoch[63] Train-accuracy=0.915000\n",
      "INFO:root:Epoch[63] Time cost=0.081\n",
      "INFO:root:Epoch[64] Train-accuracy=0.921250\n",
      "INFO:root:Epoch[64] Time cost=0.069\n",
      "INFO:root:Epoch[65] Train-accuracy=0.932500\n",
      "INFO:root:Epoch[65] Time cost=0.046\n",
      "INFO:root:Epoch[66] Train-accuracy=0.940000\n",
      "INFO:root:Epoch[66] Time cost=0.065\n",
      "INFO:root:Epoch[67] Train-accuracy=0.950000\n",
      "INFO:root:Epoch[67] Time cost=0.081\n",
      "INFO:root:Epoch[68] Train-accuracy=0.953750\n",
      "INFO:root:Epoch[68] Time cost=0.068\n",
      "INFO:root:Epoch[69] Train-accuracy=0.958750\n",
      "INFO:root:Epoch[69] Time cost=0.061\n",
      "INFO:root:Epoch[70] Train-accuracy=0.962500\n",
      "INFO:root:Epoch[70] Time cost=0.065\n",
      "INFO:root:Epoch[71] Train-accuracy=0.973750\n",
      "INFO:root:Epoch[71] Time cost=0.084\n",
      "INFO:root:Epoch[72] Train-accuracy=0.983750\n",
      "INFO:root:Epoch[72] Time cost=0.086\n",
      "INFO:root:Epoch[73] Train-accuracy=0.988750\n",
      "INFO:root:Epoch[73] Time cost=0.100\n",
      "INFO:root:Epoch[74] Train-accuracy=0.988750\n",
      "INFO:root:Epoch[74] Time cost=0.087\n",
      "INFO:root:Epoch[75] Train-accuracy=0.990000\n",
      "INFO:root:Epoch[75] Time cost=0.102\n",
      "INFO:root:Epoch[76] Train-accuracy=0.993750\n",
      "INFO:root:Epoch[76] Time cost=0.085\n",
      "INFO:root:Epoch[77] Train-accuracy=0.995000\n",
      "INFO:root:Epoch[77] Time cost=0.081\n",
      "INFO:root:Epoch[78] Train-accuracy=0.997500\n",
      "INFO:root:Epoch[78] Time cost=0.081\n",
      "INFO:root:Epoch[79] Train-accuracy=0.998750\n",
      "INFO:root:Epoch[79] Time cost=0.073\n",
      "INFO:root:Epoch[80] Train-accuracy=0.998750\n",
      "INFO:root:Epoch[80] Time cost=0.125\n",
      "INFO:root:Epoch[81] Train-accuracy=0.998750\n",
      "INFO:root:Epoch[81] Time cost=0.073\n",
      "INFO:root:Epoch[82] Train-accuracy=0.998750\n",
      "INFO:root:Epoch[82] Time cost=0.070\n",
      "INFO:root:Epoch[83] Train-accuracy=0.998750\n",
      "INFO:root:Epoch[83] Time cost=0.119\n",
      "INFO:root:Epoch[84] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[84] Time cost=0.073\n",
      "INFO:root:Epoch[85] Train-accuracy=0.998750\n",
      "INFO:root:Epoch[85] Time cost=0.105\n",
      "INFO:root:Epoch[86] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[86] Time cost=0.112\n",
      "INFO:root:Epoch[87] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[87] Time cost=0.101\n",
      "INFO:root:Epoch[88] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[88] Time cost=0.081\n",
      "INFO:root:Epoch[89] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[89] Time cost=0.070\n",
      "INFO:root:Epoch[90] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[90] Time cost=0.080\n",
      "INFO:root:Epoch[91] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[91] Time cost=0.112\n",
      "INFO:root:Epoch[92] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[92] Time cost=0.082\n",
      "INFO:root:Epoch[93] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[93] Time cost=0.082\n",
      "INFO:root:Epoch[94] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[94] Time cost=0.105\n",
      "INFO:root:Epoch[95] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[95] Time cost=0.065\n",
      "INFO:root:Epoch[96] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[96] Time cost=0.075\n",
      "INFO:root:Epoch[97] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[97] Time cost=0.170\n",
      "INFO:root:Epoch[98] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[98] Time cost=0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[99] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[99] Time cost=0.085\n"
     ]
    }
   ],
   "source": [
    "mod.fit(train_iter, num_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlIlpk2lHQhw"
   },
   "source": [
    "Как видно, на [83-84] сеть достигла точности 1.0\n",
    "\n",
    "Проверим её на наборе для аттестации.\n",
    "\n",
    "# Аттестация модели\n",
    "Теперь мы пустим новые сэмплы через сеть, те 20%, что не использовались для обучения.\n",
    "\n",
    "Сначала создадим итератор. В этот раз используем сэмплы и названия для валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w6BadBOuHDs4"
   },
   "outputs": [],
   "source": [
    "pred_iter = mx.io.NDArrayIter(data=X_valid, label=Y_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcjIaPBoJNic"
   },
   "source": [
    "Затем используем ```Module.iter_predict()``` функцию. Как только мы это сделаем, мы сравним **предсказанные названия** с **действительными**. Будем отслеживать точность аттестации, другими словами, как хорошо сеть справляется с набором для валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1531074902334,
     "user": {
      "displayName": "Глеб Кирсанов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108640698260449341450"
     },
     "user_tz": -180
    },
    "id": "ibjhCHd7IlzH",
    "outputId": "c7ff5913-c9de-4b71-aeb0-a97b00a2789c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность валидации: 0.09\n"
     ]
    }
   ],
   "source": [
    "pred_count = valid_count #всего 200 ответов\n",
    "correct_preds = total_correct_preds = 0\n",
    "\n",
    "for preds, i_batch, batch in mod.iter_predict(pred_iter):\n",
    "    label = batch.label[0].asnumpy().astype(int)\n",
    "    pred_label = preds[0].asnumpy().argmax(axis=1)\n",
    "    correct_preds = np.sum(pred_label==label)\n",
    "    total_correct_preds += correct_preds\n",
    "    \n",
    "print('Точность валидации: {0}'.format(1.0 * total_correct_preds / pred_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SniWvov_LR5-"
   },
   "source": [
    "Что тут происходит\n",
    "\n",
    "```iter_predict()``` возвращает:\n",
    "* preds - массив NDArrays. Тут он содержит один NDArray, хранящий прдесказанные названия для текущего пакета: для каждого сэмпла у нас есть предсказанные вероятности для всех 10 категорий (10х10 матрица). Итак, мы используем ```argmax()```, чтобы найти индекс наибольшего значения. pred_label это 10-элементный массив, хранящий предсказанные категории для каждого дата сэмла в текущем пакете.\n",
    "* i_batch - номер пакета\n",
    "* batch - массив NDArrays. Также содержит один NDArray для текущего пакета. Мы используем его, чтобы найти названия 10 сэмплов в пакете. Храним их в ```label``` numpy массиве (на 10 элементов).\n",
    "\n",
    "Потом, мы сравниваем номера равных значений в ```labels``` и ```pred_labels```, используя ```Numpy.sum()```.\n",
    "\n",
    "Наконец, считаем и выводим точность.\n",
    "\n",
    "Но почему 0.135%? Это действительно плохо. Если нужно было подтверждение, что данные получены случайно, то вот оно.\n",
    "\n",
    "Суть в том, что мы действительно можем обучить нейросеть чему угодно, но если данные бессмысленны (как у нас), то ничего предсказать и не выйдет. Мусор на вход - мусор на выход."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kZzzofwP7uku",
    "3BXRRlLc-UAL",
    "GJLyOh1PB6Mb",
    "T1xROa5NER8h"
   ],
   "default_view": {},
   "name": "7.1 Введение в MXNet - первая нейросеть.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
