{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "uuid_pattern = '[A-F|0-9]{32}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_for_select(table: pd.DataFrame, column: str, \n",
    "                       column_to_search: str,\n",
    "                       table_to_search: str\n",
    "                      ):\n",
    "    tribe_names = ~table[column].str.contains(uuid_pattern)\n",
    "    names = table[tribe_names][column]\n",
    "    names = names.apply(\n",
    "        lambda name: f\"(select {column} from {table_to_search} where {column_to_search} = '{name}')\"\n",
    "    )\n",
    "    table.loc[tribe_names, column] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ids_with_names(table: pd.DataFrame, ids_names: pd.DataFrame):\n",
    "    ids_names.columns = ['TRIBE_ID', 'TRIBE_NAME']\n",
    "    remove_ticks(ids_names, 'TRIBE_ID')\n",
    "    table['TRIBE_ID'] = table['TRIBE_ID'].replace(ids_names.TRIBE_ID.values, ids_names.TRIBE_NAME.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ticks(table: pd.DataFrame, column_name: str):\n",
    "    table[column_name] = table[column_name].astype(str).apply(lambda x: x.strip(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = pd.read_csv('./agile_resources_20200909.csv', sep=';', dtype=str)\n",
    "products = pd.read_csv('./MP_PRODMAN_PRODUCT.csv', sep=';', dtype=str)\n",
    "kpis = pd.read_csv('./kpi_values_cut.csv', sep=';', decimal=',')\n",
    "kpis['REPORT_DT'] = kpis.REPORT_DT.apply(lambda date: f\"TO_DATE('{date}', 'DD.MM.YYYY HH24:MI')\")\n",
    "\n",
    "replace_ids_with_names(resources, pd.read_csv('./MP_PRODMAN_TRIBE.csv', sep=','))\n",
    "resources = resources.drop_duplicates(subset=['PRODUCT_NAME', 'TRIBE_ID', 'TEAM_ID', \n",
    "                                              'RESOURCE_TYPE_ID', 'RESOURCE_DESC_ID'])\n",
    "\n",
    "products = products.drop(columns=['TRIBE_ID'])\n",
    "kpis = kpis.drop(columns=['KPI_VALUES_CUT_ID', 'PRODUCT_KPI_ID', 'Unnamed: 7'])\n",
    "kpis = kpis.dropna(subset=['VALUE_AMT'])\n",
    "kpis['VALUE_AMT'] = kpis.VALUE_AMT.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row(x: pd.Series):\n",
    "    x = x.copy()\n",
    "    where = f\"where PRODUCT_NAME = '{x.PRODUCT_NAME}' and FUNC_BLOCK_ID = '{x.FUNC_BLOCK_ID}'\"\n",
    "    x[x.str.contains(uuid_pattern)] = x[x.str.contains(uuid_pattern)].apply(lambda x: f\"'{x}'\")\n",
    "    product_query = f\"(select PRODUCT_ID from MP_PRODMAN.PRODUCT {where})\"\n",
    "    tuples = zip(columns, [x.TRIBE_ID, x.TEAM_ID, x.RESOURCE_TYPE_ID, x.RESOURCE_DESC_ID, product_query])\n",
    "    where  = list(map(lambda f: f'{f[0]} = {f[1]}', tuples))\n",
    "    where[-1] += kek\n",
    "    return pd.Series([x.AGILE_RESOURCE_ID, query.format(values=' and '.join(where))])\n",
    "\n",
    "remove_ticks(products, 'FUNC_BLOCK_ID')\n",
    "merged = pd.merge(resources, products, on='PRODUCT_NAME')\n",
    "merged[:]['AGILE_RESOURCE_ID'] = merged['AGILE_RESOURCE_ID'].astype(int)\n",
    "replace_for_select(merged, 'TRIBE_ID', 'TRIBE_NAME', 'MP_PRODMAN.TRIBE')\n",
    "replace_for_select(merged, 'TEAM_ID', 'TEAM_SAP_CODE', 'MP_PRODMAN.TEAM')\n",
    "\n",
    "kek = ' and AGILE_INITIATIVE_ID is NULL and ORG_ED_ID is NULL and IT_SERVICE_ID is NULL and MERGE_OP_ID is NULL and EFFECT_TYPE_ID is NULL'\n",
    "to_insert_resources = pd.DataFrame(merged, columns=merged.columns)\n",
    "columns = list(to_insert_resources.columns[2:-1]) + ['PRODUCT_ID']\n",
    "query = 'select AGILE_RESOURCE_ID from MP_PRODMAN.AGILE_RESOURCE where {values}'\n",
    "querries = to_insert_resources.apply(row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "querries.columns = ['AGILE_RESOURCE_ID', 'QUERY']\n",
    "querries.loc[:, 'AGILE_RESOURCE_ID'] = querries['AGILE_RESOURCE_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_kpis = pd.merge(kpis, querries, on='AGILE_RESOURCE_ID')\n",
    "merged_kpis['AGILE_RESOURCE_ID'] = merged_kpis['QUERY']\n",
    "merged_kpis = merged_kpis.drop(columns='QUERY')\n",
    "merged_kpis['AGILE_RESOURCE_ID'] = merged_kpis['AGILE_RESOURCE_ID'].apply(lambda x: f'({x})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ADD_KPIS.sql', 'w') as f:\n",
    "    rows = []\n",
    "    def row(x: pd.Series):\n",
    "        x = x.copy().astype(str)\n",
    "        x[to_tick] = x[to_tick].apply(lambda x: f\"'{x}'\")\n",
    "        values = [x[value] for value in columns]\n",
    "        rows.append(query.format(values=', '.join(values)))\n",
    "        if len(rows) > 1000:\n",
    "            f.write('\\n'.join(rows))\n",
    "            rows.clear()\n",
    "\n",
    "    to_tick = [1, 2]\n",
    "    columns = merged_kpis.columns\n",
    "    headers = ', '.join(columns)\n",
    "    query = f'insert into MP_PRODMAN.KPI_VALUES_CUTS ({headers})' + ' values ({values});'\n",
    "    merged_kpis.apply(row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "141376    None\n",
       "141377    None\n",
       "141378    None\n",
       "141379    None\n",
       "141380    None\n",
       "Length: 141381, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row(x: pd.Series):\n",
    "    x = x.copy().astype(str)\n",
    "    x[to_tick] = x[to_tick].apply(lambda x: f\"'{x}'\")\n",
    "    values = [x[value] for value in columns]\n",
    "    lines.append(query.format(values=', '.join(values)))\n",
    "\n",
    "lines = []\n",
    "to_tick = [1, 2]\n",
    "columns = merged_kpis.columns\n",
    "headers = ', '.join(columns)\n",
    "query = f'insert into MP_PRODMAN.KPI_VALUES_CUTS ({headers})' + ' values ({values});'\n",
    "merged_kpis.apply(row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "r = r'(insert into).*(VALUE_AMT, FACT_PLAN_FLAG, CUT_TYPE, REPORT_DT, AGILE_RESOURCE_ID).*\\((\\d*, .*)\\)'\n",
    "\n",
    "column_names = 'VALUE_AMT, FACT_PLAN_FLAG, CUT_TYPE, REPORT_DT, AGILE_RESOURCE_ID'\n",
    "\n",
    "\n",
    "partition = f'PARTITION BY {column_names} ORDER BY {column_names}'\n",
    "start = 'delete from MP_PRODMAN.KPI_VALUES_CUTS where KPI_VALUES_CUT_ID in'\n",
    "small_select = f'select KPI_VALUES_CUT_ID, row_number() over ({partition}) R from MP_PRODMAN.KPI_VALUES_CUTS'\n",
    "huge_select = f'select KPI_VALUES_CUT_ID from ({small_select}'\n",
    "new_query = f\"{start} ({huge_select}\"\n",
    "queries_for_delete = []\n",
    "summator = 0\n",
    "for key, value in Counter(lines).items():\n",
    "    if value > 1:\n",
    "        fields = list(map(str.strip, re.search(r, key).group(2).split(',')))\n",
    "        values = list(map(str.strip, re.search(r, key).group(3).split(',', maxsplit=5)))\n",
    "        values[3] = ', '.join(values[3:5])\n",
    "        values[4] = values[-1]\n",
    "        connect = zip(fields, values)\n",
    "        where = 'where ' + ' and '.join(list(map(lambda x: f'{x[0]} = {x[1]}', connect)))\n",
    "        queries_for_delete.append(f'{new_query} {where}) where R > 1);')\n",
    "        summator += value - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DELETE_KPI.sql', 'w') as f:\n",
    "    f.write('\\n'.join(queries_for_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "prev = 0\n",
    "part = len(queries_for_delete) // 4\n",
    "for i in range(4):\n",
    "    next = prev + part\n",
    "    parts.append(queries_for_delete[prev:next])\n",
    "    prev += part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, part in enumerate(parts):\n",
    "    with open(f'DELETE_KPI_{i}.sql', 'w') as f:\n",
    "        f.write('\\n'.join(part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
