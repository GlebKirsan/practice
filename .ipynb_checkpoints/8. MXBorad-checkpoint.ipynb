{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация обучения\n",
    "На некоторых этапах бывает полезно для отладки изобразить, как изменяется точность, как меняются веса слоёв, что поступает на вход. В этом может помочь tensorboard.\n",
    "\n",
    "Что нам понадобится установить: \n",
    "* tensorflow\n",
    "* tensorboard\n",
    "* mxboard\n",
    "\n",
    "Будем смотреть на примере предыдущего ноутбука с набором данных MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxboard import SummaryWriter #то, что понадобится для визуализации\n",
    "import os #потребуется для сохранения логов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MXNet для отладки предоставляет callback функции, которые можно вызывать под конец эпохи, при валидации, под конец пакета данных. \n",
    "\n",
    "Создадим три функции:\n",
    "* metrics_check будет в конце каждой валидации сохранять число-метрику, которую потом мы отобразим на графике\n",
    "* first_epoch_images покажет, какие изображения передавались на первой эпохе\n",
    "* epoch_end_results будет сохранять гистограммы, как меняются веса и отклонения слоёв в течение всего процесса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_check(*args):\n",
    "    '''\n",
    "    Примерный список входных вариантов такой:\n",
    "    (номер_эпохи, номер_пакета, метрики, заголовки={\n",
    "    пакет данных и т.д.\n",
    "    })\n",
    "    Для более подробной информации можно вывести аргументы функцикей print\n",
    "    '''\n",
    "    args = args[0] #получаем кортеж аргументов\n",
    "    epoch = args[0] #получаем номер текущей эпохи\n",
    "    metrics = args[2] #извлекаем метрики\n",
    "    for name, value in metrics.get_name_value(): #возвращает лист кортежей вида (название, значение)\n",
    "        #функция создаёт график, шагом построения точек выбираем эпоху\n",
    "        summary_writer.add_scalar(tag=name,\n",
    "                                  value=value,\n",
    "                                  global_step=epoch)\n",
    "        \n",
    "        \n",
    "def first_epoch_images(*args):\n",
    "    args = args[0]\n",
    "    epoch = args[0]\n",
    "    if epoch != 0: #если эпоха не первая, то сохранять изображения не нужно\n",
    "        return\n",
    "    num_batch = args[1] #номер пакета в первой эпохе будет нашим шагом сохранения изображений\n",
    "    data = args[3]['data_batch'].data #достаём из заголовков\n",
    "    summary_writer.add_image(tag='images_per_epoch',\n",
    "                             image=data[0]/256, #функция принимает матрицы, где значения от 0 до 1\n",
    "                             global_step=num_batch)\n",
    "    \n",
    "    \n",
    "def epoch_end_results(*args):\n",
    "    epoch = args[0]\n",
    "    layers = args[2] #получение словаря вида {слой_вес/отклонение: значения}\n",
    "    for key, value in layers.items():\n",
    "        summary_writer.add_histogram(tag=key,\n",
    "                                     values=value,\n",
    "                                     global_step=epoch,\n",
    "                                     bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же для простоты кода добавим две функции, перезагружающие параметры для каждого из входных значений скорости обучения (0.1, 0.01, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(learning_rate):\n",
    "    train_iter.reset()\n",
    "    valid_iter.reset()\n",
    "    summary_writer.add_graph(mlp) #сохраним граф наших слоёв\n",
    "    mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "    mod.init_params(force_init=True,\n",
    "                    initializer=mx.initializer.Xavier(magnitude=2.))\n",
    "    mod.init_optimizer(force_init=True,\n",
    "                       optimizer='sgd',\n",
    "                       optimizer_params={'learning_rate': learning_rate})\n",
    "\n",
    "\n",
    "def start_train(epochs):\n",
    "    mod.fit(train_data=train_iter,\n",
    "            eval_data=valid_iter,\n",
    "            eval_metric=['loss', 'acc'], #нас будут интересовать потери на каждой эпохе и точность\n",
    "            eval_end_callback=metrics_check, #функциям callback можно передать список функций для вызова\n",
    "                                             #данная вызовется под конец валидации\n",
    "            batch_end_callback=first_epoch_images, #под конец пакета\n",
    "            epoch_end_callback=epoch_end_results, #под конец эпохи\n",
    "            num_epoch=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проинициализируем слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "data = mx.sym.Flatten(data=data)\n",
    "fc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "fc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden=10)\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "mod = mx.mod.Module(mlp) #mlp - multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = mx.io.ImageRecordIter(path_imglist='./mnist_train.lst', \n",
    "                                   path_imgrec='./mnist_train.rec',\n",
    "                                   data_shape=(1, 28, 28),\n",
    "                                   batch_size=100)\n",
    "\n",
    "valid_iter = mx.io.ImageRecordIter(path_imglist='./mnist_test.lst', \n",
    "                                   path_imgrec='./mnist_test.rec',\n",
    "                                   data_shape=(1, 28, 28),\n",
    "                                   batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём тот же эксперимент, но для большего количества эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mxboard.event_file_writer:successfully opened events file: /home/gleb/logs/learning_rate=0.1/events.out.tfevents.1531735715.glkv\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/gleb/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:mxboard.event_file_writer:wrote 40 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 45 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 51 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 52 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 43 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 47 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 49 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 26 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 14 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 17 events to disk\n",
      "WARNING:root:Already bound, ignoring bind()\n",
      "INFO:mxboard.event_file_writer:successfully opened events file: /home/gleb/logs/learning_rate=0.01/events.out.tfevents.1531735760.glkv\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:mxboard.event_file_writer:wrote 46 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 45 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 47 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 50 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 40 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 40 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 43 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 36 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 14 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 5 events to disk\n",
      "WARNING:root:Already bound, ignoring bind()\n",
      "INFO:mxboard.event_file_writer:successfully opened events file: /home/gleb/logs/learning_rate=0.001/events.out.tfevents.1531735806.glkv\n",
      "WARNING:root:Already bound, ignoring bind()\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "INFO:mxboard.event_file_writer:wrote 40 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 46 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 40 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 42 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 33 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 41 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 43 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 41 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 29 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 12 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 11 events to disk\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.1, 0.01, 0.001]\n",
    "num_of_epochs = [20, 20, 25]\n",
    "#домашняя директория, например, куда будут сохраняться логи для последующей визуализации\n",
    "logdir = os.path.join(os.environ['HOME'] + '/logs/learning_rate=')\n",
    "for lr, epochs in zip(learning_rate, num_of_epochs):\n",
    "    #создадим для каждого значения lr отдельную папку логов\n",
    "    #и в конце каждого обучения будем закрывать summary_writer благодаря with\n",
    "    with SummaryWriter(logdir + str(lr), flush_secs=3) as summary_writer:\n",
    "        reset_params(lr)\n",
    "        start_train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, в консоли укажем папку logs для запуска tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.9.0 at http://glkv:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "tens_logs = os.path.join(os.environ[\"HOME\"], 'logs/')\n",
    "!tensorboard --logdir=$tens_logs #через ! команды отправляются в командную строку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты.\n",
    "Точность не растёт лишь у первого эксперимента. Функция потерь также отмечает изменения.\n",
    "<img src=\"images/pic1.png\">\n",
    "На первом слое отклонения в первом случае(lr=0.1) смещены от нуля примерно на 2.10, а веса - на -376. Т.е. сеть не может попасть с таким большим шагом обучения в нужные веса.\n",
    "<img src=\"images/pic2.png\">\n",
    "На третьей картине так же, как и на второй, при lr=0.1 веса имеют слишком большое значение(333), что не позволяет нейросети делать верные выводы о предоставляемых данных.\n",
    "<img src=\"images/pic3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение обученной нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#будем делать чекпоинт после каждой эпохи(можно задать самим)\n",
    "model_prefix = 'mnist_net'\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "INFO:mxboard.event_file_writer:successfully opened events file: /home/gleb/logs/learning_rate=0.0001/events.out.tfevents.1531737737.glkv\n",
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/gleb/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "INFO:mxboard.event_file_writer:wrote 41 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 38 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 45 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 44 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 38 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 36 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 37 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 38 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 30 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 8 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 16 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 12 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 8 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 10 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 8 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 18 events to disk\n",
      "INFO:mxboard.event_file_writer:wrote 5 events to disk\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001 #для интереса попробуем ещё меньшую скорость обучения\n",
    "epochs = 25\n",
    "with SummaryWriter(logdir + str(lr), flush_secs=3) as summary_writer:\n",
    "    reset_params(lr)\n",
    "    mod.fit(train_data=train_iter,\n",
    "            eval_data=valid_iter,\n",
    "            eval_metric=['loss', 'acc'],\n",
    "            eval_end_callback=metrics_check,\n",
    "            batch_end_callback=first_epoch_images,\n",
    "            epoch_end_callback=[epoch_end_results, checkpoint], #передадим лист с функциями, где есть чекпоинт\n",
    "            num_epoch=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В папке с ноутбуком будут храниться сохранённые параметры модели для каждой эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузка состояния модели для третьей эпохи\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, 3) \n",
    "\n",
    "#print(arg_params) #вывод параметров, передаются веса и отклонения на загруженной эпохе\n",
    "mod.set_params(arg_params, aux_params)\n",
    "#продолжим обучение с третьей эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=sym) #присвоим новый Символ модели\n",
    "# assign the loaded parameters to the module\n",
    "mod.fit(train_iter,\n",
    "        num_epoch=25,\n",
    "        begin_epoch=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
